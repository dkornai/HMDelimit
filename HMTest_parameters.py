'''
THIS MODULE DEMONSTRATES HOW TO CHECK FOR THE REQUIRED SAMPLE SIZES TO REACH PARAMETER STABILITY
'''

## DEPENDENCIES
import copy
import os
import re
import shutil
from itertools import repeat
import multiprocessing as mp

import numpy as np

from helper_functions import BPP_run_capture
from helper_functions import dict_to_bppcfile
from helper_functions import BPP_summary
from helper_functions import BPP_resume_capture
from helper_functions import path_filename

from data_dicts import clprnt

from align_imap_module import autoPopParam
from align_imap_module import autoPrior





# collect the values of the parameters produced by BPP
def get_parameters_from_MCMC():
    full_out = BPP_summary("bpp.ctl")
    lines = full_out.split("\n")
    
    def extract_list(keyword, sourcelines):
        r = re.compile(keyword)
        line = list(filter(r.match, sourcelines))[0]
        line = line.split()[1:-1]
        line = [float(value) for value in line]
        
        return line
    
    means = extract_list("mean ", lines)

    return means

# estimate the Relative Error based on the parameter values generated by the independent runs
def calculate_difference_ratio(parameter_list):
    results = []
    for i in range(len(parameter_list[0])):
        values = [parameter_list[j][i] for j in range(len(parameter_list))]
        mean = np.mean(values)
        diff_from_mean = [abs(mean-value)/mean for value in values]
        ratio = np.round(np.mean(diff_from_mean), decimals = 2)
        results.append(ratio)

    return results


std_cfile = {'seed': '-1',
             'outfile': 'out.txt', 
             'mcmcfile': 'mcmc.txt', 
             'speciesdelimitation': '0', 
             'speciestree': '0', 
             'usedata': '1', 
             'locusrate': '0', 
             'cleandata': '0', 
             'print': '1 0 0 0', 
             'sampfreq': '1', 
            }

iteration_size = 10000

# perform the iterations from the burn in up to and including the first checkpoint
def generate_param_burinin(guide_tree, imapfile, seqfile, smpl, priors, core_offset, index):
    pop_param = autoPopParam(imapfile, seqfile)
    cdict = copy.deepcopy(std_cfile)
    cdict["nsample"] = smpl
    cdict["burnin"] = iteration_size
    cdict["seqfile"] = f"../{seqfile}"
    cdict["imapfile"] = f"../{imapfile}"
    cdict["threads"] = f"2 {int(np.round(((index+0.5)*2), decimals = 2)+ core_offset )}"
    cdict['species&tree'] = pop_param["species&tree"]
    cdict['popsizes'] = pop_param["popsizes"]
    cdict["newick"] = guide_tree
    cdict['nloci'] = pop_param['nloci']
    cdict["thetaprior"] = priors['thetaprior']
    cdict["tauprior"] = priors['tauprior']
    cdict["checkpoint"] = f"{iteration_size*2} {iteration_size}"
    
    folder_name = f"replicate_{index}"
    os.mkdir(folder_name)
    os.chdir(folder_name)
    dict_to_bppcfile(cdict, "bpp.ctl")
    BPP_run_capture("bpp.ctl", index)
    parameters = get_parameters_from_MCMC()
    
    os.chdir("..")
    
    return parameters

# iterate the parameter values by extending the BPP run by X samples
def iterate_param_from_chk(input_folder):
    os.chdir(input_folder)
    
    ls = os.listdir()
    chk_filenames = [file for file in ls if ".chk" in str(file)]
    chk_maxval = max([int(filename.split(".")[-2]) for filename in chk_filenames])
    chk_filename = f"out.txt.{chk_maxval}.chk"
    
    BPP_resume_capture(chk_filename, input_folder.split("_")[-1])
    parameters = get_parameters_from_MCMC()
    os.chdir("..")
    
    return parameters

# main function implementing the Relative Error checking
def test_param(imapfile, seqfile, guide_tree, working_dir, repeats, smpl, core_offset = 0):
    # customized user feedback displayed in the terminal, and written to the output file
    def uncerteanty_feedback(parameter_array, diff_array, median_array, mean_array, samples):
        text = ""
        text += f"Values after {samples} samples\n"
        for values in parameter_array[-1]: text += f"{str(values)[1:-1]}\n"
        text += f"Estimated RE of individual values after {samples} samples\n"
        text += f"{str(diff_array[-1])[1:-1]}\n"
        text += f"Median RE: {median_array[-1]} Mean RE: {mean_array[-1]}\n"
        print(f"{clprnt.GREEN}", end = "\n")
        print(text)
        print(f"{clprnt.end}", end = "")

        return text

    # set up working directory
    parent_dir = os.getcwd()
    os.mkdir(working_dir)
    shutil.copy(src = seqfile,  dst = working_dir)
    shutil.copy(src = imapfile, dst = working_dir)
    os.chdir(working_dir)
    imapfile = path_filename(imapfile)
    seqfile = path_filename(seqfile)

    # set up output files
    with open("summary_precision.csv","w") as summ_file:
        summ_file.write("median RE, mean RE, samples\n")
    with open("detailed_precision.txt","w") as summ_file:
        summ_file.write("")
    
    # set up commonly used priors
    priors = autoPrior(imapfile, seqfile)

    # set up array to hold parameter results
    param_array = []
    param_diff = []
    param_median = []
    param_mean = []

    # run the first iteration to start
    pool = mp.Pool(mp.cpu_count())
    treeindex = list(range(repeats))
    new_params = pool.starmap(  generate_param_burinin, 
                                zip(repeat(guide_tree), 
                                    repeat(imapfile), 
                                    repeat(seqfile), 
                                    repeat(smpl), 
                                    repeat(priors),
                                    repeat(core_offset), 
                                    treeindex))
    pool.close()
    # collect the RE values
    param_array.append(new_params)
    param_diff.append(calculate_difference_ratio(param_array[-1]))
    param_median.append(np.round(np.median(param_diff[-1]), decimals = 2))
    param_mean.append(np.round(np.mean(param_diff[-1]), decimals = 2))
    fb = uncerteanty_feedback(param_array, param_diff, param_median, param_mean, iteration_size)

    with open("summary_precision.csv","a") as summ_file:
        summ_file.write(f"{param_median[-1]}, {param_mean[-1]}, {iteration_size}\n")
    with open("detailed_precision.txt","a") as summ_file:
        summ_file.write(fb)

    # run the subsequent resume iterations
    folder_names = [f"replicate_{index}" for index in range(repeats)]
    iteration = 2
    thresholds_met = False
    
    while iteration*iteration_size <= smpl and thresholds_met == False:
        # run the data generation in multithreaded mode
        pool = mp.Pool(mp.cpu_count())
        treeindex = list(range(repeats))
        new_params = pool.starmap(iterate_param_from_chk, zip(folder_names))
        pool.close()
        
        # collect the RE values  
        param_array.append(new_params)
        param_diff.append(calculate_difference_ratio(param_array[-1]))
        param_median.append(np.round(np.median(param_diff[-1]), decimals = 2))
        param_mean.append(np.round(np.mean(param_diff[-1]), decimals = 2))
        fb = uncerteanty_feedback(param_array, param_diff, param_median, param_mean, iteration_size*iteration)
        
        # write to files
        with open("summary_precision.csv","a") as summ_file:
            summ_file.write(f"{param_median[-1]}, {param_mean[-1]}, {iteration_size*iteration}\n")
        with open("detailed_precision.txt","a") as summ_file:
            summ_file.write(fb)

        # check if sufficient precision is reached when median RE <= 0.01 mean RE <= 0.05
        if param_median[-1] <= 0.01 and param_mean[-1] <= 0.05:
            thresholds_met = True

        iteration += 1
   
    os.chdir(parent_dir)    


## EXAMPLE CALCULATIONS

# test_param  (
#     "Test_Data/HLizard_2009/D_HL_imap.txt",
#     "Test_Data/HLizard_2009/D_HL_align.txt", 
#     "((CBC, ((NBC, SCA), NCA)), SBC);",
#     "Test_Results/hliz_param",
#     4, 200000,
#     core_offset=4
#             )

# test_param  (
#     "Test_Data/TMS_2019/D_TMS_imap.txt",
#     "Test_Data/TMS_2019/D_TMS_align.txt", 
#     "(((A, B), (C, D)), X);",
#     "Test_Results/tms_par",
#     6, 200000,
#     core_offset=0
#             )